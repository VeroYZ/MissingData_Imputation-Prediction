{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a2c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b50b0",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dedc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1_Lab_1=pd.read_excel(\"A1_Lab-1.xlsx\")\n",
    "A1_Lab_2=pd.read_excel(\"A1_Lab-2.xlsx\")\n",
    "A2_Lab_1=pd.read_excel(\"A2_Lab-1.xlsx\")\n",
    "A2_Lab_2=pd.read_excel(\"A2_Lab-2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155afaba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "well_A1=A1_Lab_1.merge(A1_Lab_2, how='outer', on='Depth',sort=True,suffixes=('', '_LAB-2')).assign(WELL='Well_A1')\n",
    "depth_A1=well_A1['Depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead56862",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_A2=A2_Lab_1.merge(A2_Lab_2, how='outer', on='Depth',sort=True, suffixes=('', '_LAB-2')).assign(WELL='Well_A2')\n",
    "depth_A2=well_A2['Depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf8c475",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_AA=pd.concat([well_A1,well_A2])\n",
    "set_AA.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9ecc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_encoder = OrdinalEncoder(categories=[[\"Well_A1\", \"Well_A2\"]])\n",
    "well_encoder.fit(set_AA[[\"WELL\"]])\n",
    "set_AA[\"Well\"] = well_encoder.transform(set_AA[[\"WELL\"]])\n",
    "set_AA=set_AA.drop(['Depth','WELL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf8f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_NaN=set_AA.dropna()\n",
    "No_NaN.reset_index(drop=True, inplace=True)\n",
    "No_NaN.to_excel('set_AA-No_NaN.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0843f3a",
   "metadata": {},
   "source": [
    "### Set_AA NaN figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3b8165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_AA_figure=set_AA.copy()\n",
    "set_AA_figure.index += 1\n",
    "\n",
    "set_AA_figure.columns=set_AA_figure.columns.str.replace('_LAB-2','')\n",
    "\n",
    "plt.figure(figsize=(20, 15), dpi = 500)\n",
    "\n",
    "colors = [\"#6E9FD0\", \"black\"]\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "plt.rcParams['font.family'] = 'arial'\n",
    "\n",
    "sns.heatmap(set_AA_figure.isnull(), cbar=False, cmap=cmap, yticklabels=115)\n",
    "\n",
    "plt.xticks(fontsize=14, rotation=90)\n",
    "plt.yticks(fontsize=14, rotation=0)\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc80c4",
   "metadata": {},
   "source": [
    "### New NaN data (creating manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6933e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"New_NaN.xlsx\").drop(['Depth'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da0a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Well\"] = well_encoder.transform(df[[\"WELL\"]])\n",
    "df=df.drop('WELL', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21eca78",
   "metadata": {},
   "source": [
    "### Set_AA' NaN figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e143586b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_figure=df.copy()\n",
    "df_figure.index += 1\n",
    "df_figure.columns=df_figure.columns.str.replace('_LAB-2','')\n",
    "\n",
    "plt.figure(figsize=(20, 15), dpi = 500)\n",
    "\n",
    "colors = [\"#6E9FD0\", \"black\"]\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "plt.rcParams['font.family'] = 'arial'\n",
    "\n",
    "sns.heatmap(df_figure.isnull(), cbar=False, cmap=cmap, yticklabels=42, linewidth=.8)\n",
    "\n",
    "plt.xticks(fontsize=14, rotation=90)\n",
    "plt.yticks(fontsize=14, rotation=0)\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e708b8",
   "metadata": {},
   "source": [
    "## VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c317321",
   "metadata": {},
   "source": [
    "### 1) Validation using LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2809ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOOCV_scores(Imp_model,model_name):\n",
    "    \n",
    "    def NRMSE_Scorer(y_true, y_pred):\n",
    "        rmse = mean_squared_error(\n",
    "        y_true  = y_true,\n",
    "        y_pred  = y_pred,\n",
    "        squared = False\n",
    "           )\n",
    "    \n",
    "        nrmse = rmse/(y.max()-y.min())    \n",
    "    \n",
    "        return nrmse\n",
    "\n",
    "    nrmse_score = make_scorer(NRMSE_Scorer, greater_is_better = False)\n",
    "\n",
    "    scores_1=pd.DataFrame()\n",
    "    scores_2=pd.DataFrame()\n",
    "    \n",
    "    y_hats=Imp_model.loc[:,['Al2O3_LAB-2', 'SiO2_LAB-2', 'TiO2_LAB-2', 'Fe2O3_LAB-2', 'CaO_LAB-2', 'K2O_LAB-2']]\n",
    "\n",
    "    for col in y_hats:\n",
    "        X=Imp_model.iloc[:,0:29]\n",
    "        y=y_hats[col]\n",
    "        \n",
    "        cv = LeaveOneOut()\n",
    "        \n",
    "        scoring= [nrmse_score, 'neg_mean_absolute_error']\n",
    "    \n",
    "        model = RandomForestRegressor(random_state=123, max_features=25, n_estimators= 150)\n",
    "        \n",
    "        for score in scoring:\n",
    "            scores = cross_val_score(model, X, y, scoring=score, cv=cv)\n",
    "            scores = absolute(scores)\n",
    "            if score=='neg_mean_absolute_error':\n",
    "                scores_1= scores_1.append({'Feature': col, f'MAE_{model_name}':mean(scores)}, ignore_index=True)\n",
    "            else:\n",
    "                scores_2= scores_2.append({f'NRMSE_{model_name}':mean(scores)}, ignore_index=True)\n",
    "        \n",
    "\n",
    "    Final_Scores=pd.concat([scores_1,scores_2], axis=1)       \n",
    "        \n",
    "    return Final_Scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e137f8c",
   "metadata": {},
   "source": [
    "### 2) Validation of real versus predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a7f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_pred(Imp_model, model_name):\n",
    "    nan=pd.isnull(df)\n",
    "    nan= nan[nan.iloc[:,1] == True]\n",
    "    indices=list(nan.index)\n",
    "    \n",
    "    real = No_NaN.loc[indices]    \n",
    "    pred = Imp_model.loc[indices]\n",
    "    \n",
    "    error=pd.DataFrame()\n",
    "\n",
    "    for i in real.columns[0:29]:\n",
    "        \n",
    "        rmse = mean_squared_error(\n",
    "            y_true  = real[i],\n",
    "            y_pred  = pred[i],\n",
    "            squared = False\n",
    "           )\n",
    "                \n",
    "        nrmse = rmse/(real[i].max()-real[i].min())     \n",
    "       \n",
    "        \n",
    "        error= error.append({'Variable': i,f'RMSE_{model_name}': rmse.round(6), f'NRMSE_{model_name}': nrmse.round(6)},\n",
    "                            ignore_index=True)\n",
    "        \n",
    "    \n",
    "    return error          \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d1e3d5",
   "metadata": {},
   "source": [
    "### 3) Validation using a Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GS_scores(Imp_model,model_name):\n",
    "    \n",
    "    y_hats=Imp_model.loc[:,['Al2O3_LAB-2', 'SiO2_LAB-2', 'TiO2_LAB-2', 'Fe2O3_LAB-2', 'CaO_LAB-2', 'K2O_LAB-2']]\n",
    "    y_hats.drop([49,53,76,155],axis=0, inplace=True)\n",
    "    \n",
    "    Imp_model.drop([49,53,76,155],axis=0,inplace=True)\n",
    "    \n",
    "    final_scores=pd.DataFrame()    \n",
    "    \n",
    "    for col in y_hats:\n",
    "        X=Imp_model.iloc[:,0:29]\n",
    "        y=y_hats[col]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                            X,\n",
    "                                            y,\n",
    "                                            train_size   = 0.7,\n",
    "                                            random_state = 123,\n",
    "                                            shuffle      = True\n",
    "                                        )\n",
    "    \n",
    "        # Evaluated Hyperparameters \n",
    "        param_grid = {'n_estimators': [30,70,150],\n",
    "                      'max_features': [5, 10, 25],\n",
    "                      'max_depth'   : [None, 3, 10, 20]\n",
    "                         }\n",
    "\n",
    "        # Grid    \n",
    "        grid = GridSearchCV(\n",
    "                estimator  = RandomForestRegressor(random_state = 123),\n",
    "                param_grid = param_grid,\n",
    "                scoring    = 'neg_root_mean_squared_error',\n",
    "                n_jobs     = - 1,\n",
    "                cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "                refit      = True,\n",
    "                verbose    = 0,\n",
    "                return_train_score = True\n",
    "                )\n",
    "        \n",
    "\n",
    "        grid.fit(X = X_train, y = y_train)\n",
    "      \n",
    "        # Final model\n",
    "            \n",
    "        final_model = grid.best_estimator_\n",
    "        predicted = final_model.predict(X = X_test)\n",
    "    \n",
    "        rmse = mean_squared_error(\n",
    "            y_true  = y_test,\n",
    "            y_pred  = predicted,\n",
    "            squared = False\n",
    "           )\n",
    "            \n",
    "        nrmse = rmse/(y_test.max()-y_test.min())    \n",
    "       \n",
    "    \n",
    "        final_scores= final_scores.append({'Feature': col,f'RMSE_{model_name}': rmse.round(6),\n",
    "                                           f'NRMSE_{model_name}': nrmse.round(6)},ignore_index=True)\n",
    "    \n",
    "    \n",
    "    return final_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc546f",
   "metadata": {},
   "source": [
    "## IMPUTATION TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edb545c",
   "metadata": {},
   "source": [
    "## MICE with Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e00639",
   "metadata": {},
   "source": [
    "### 1) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3edd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a215ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "df_scaled = pd.DataFrame(df_scaled, columns = df.columns)\n",
    "na_loc = df_scaled.isnull()\n",
    "df_scaled[na_loc] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d23d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=LinearRegression()\n",
    "\n",
    "Impute=IterativeImputer(estimator=LR,\n",
    "                        missing_values=np.nan,\n",
    "                        max_iter=5,\n",
    "                        verbose=2,\n",
    "                        imputation_order='roman',\n",
    "                        random_state=0\n",
    "                       )\n",
    "\n",
    "ImputedData=Impute.fit_transform(df_scaled)\n",
    "\n",
    "LR_IMP=pd.DataFrame(scaler.inverse_transform(ImputedData), columns=df.columns)\n",
    "\n",
    "# Validation\n",
    "\n",
    "LOOCV_scores(LR_IMP, 'LR')\n",
    "\n",
    "real_pred(LR_IMP,'LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2873f0f2",
   "metadata": {},
   "source": [
    "### 2) Imputation of the actual missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1300ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_AA_scaled=scaler.fit_transform(set_AA)\n",
    "set_AA_scaled = pd.DataFrame(set_AA_scaled, columns = set_AA.columns)\n",
    "na_loc = set_AA_scaled.isnull()\n",
    "set_AA_scaled[na_loc] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effcad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Imputed_set_AA=Impute.transform(set_AA_scaled)\n",
    "set_AA_LR_IMP=pd.DataFrame(scaler.inverse_transform(Imputed_set_AA), columns=set_AA.columns)\n",
    "\n",
    "# Validation\n",
    "\n",
    "GS_scores(set_AA_LR_IMP,'LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07ee4d3",
   "metadata": {},
   "source": [
    "## Miceforest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e83b132",
   "metadata": {},
   "source": [
    "### 1) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1087f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import miceforest as mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e62d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "df_scaled = pd.DataFrame(df_scaled, columns = df.columns)\n",
    "na_loc = df_scaled.isnull()\n",
    "df_scaled[na_loc] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab817b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel=mf.ImputationKernel(df_scaled,\n",
    "                           datasets=10,\n",
    "                           save_all_iterations=True,\n",
    "                           random_state=11\n",
    "                          )\n",
    "\n",
    "optimal_parameters, losses = kernel.tune_parameters(dataset=0,\n",
    "                                                    optimization_steps=15,\n",
    "                                                    random_state=11\n",
    "                                                   )\n",
    "\n",
    "kernel.mice(6, variable_parameters= optimal_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_1=pd.DataFrame(scaler.inverse_transform(kernel.complete_data(1)),columns=df.columns)\n",
    "unscaled_2=pd.DataFrame(scaler.inverse_transform(kernel.complete_data(2)),columns=df.columns)\n",
    "unscaled_3=pd.DataFrame(scaler.inverse_transform(kernel.complete_data(3)),columns=df.columns)\n",
    "unscaled_4=pd.DataFrame(scaler.inverse_transform(kernel.complete_data(4)),columns=df.columns)\n",
    "unscaled_5=pd.DataFrame(scaler.inverse_transform(kernel.complete_data(5)),columns=df.columns)\n",
    "unscaled_6=pd.DataFrame(scaler.inverse_transform(kernel.complete_data(6)),columns=df.columns)\n",
    "unscaled_7=pd.DataFrame(scaler.inverse_transform(kernel.complete_data(7)),columns=df.columns)\n",
    "unscaled_8=pd.DataFrame(scaler.inverse_transform(kernel.complete_data(8)),columns=df.columns)\n",
    "unscaled_9=pd.DataFrame(scaler.inverse_transform(kernel.complete_data(9)),columns=df.columns)\n",
    "unscaled_0=pd.DataFrame(scaler.inverse_transform(kernel.complete_data(0)),columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc59d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_Imp=pd.concat([unscaled_0,unscaled_1,unscaled_2,unscaled_3,unscaled_4,unscaled_5,unscaled_6,unscaled_7,\n",
    "                      unscaled_8,unscaled_9],).groupby(level=0).mean()\n",
    "\n",
    "# Validtion\n",
    "\n",
    "LOOCV_scores(MF_Imp,'MF')\n",
    "\n",
    "real_pred(MF_Imp, 'MF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b18d7a",
   "metadata": {},
   "source": [
    "### 2) Imputation of the actual missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_AA_scaled=scaler.fit_transform(set_AA)\n",
    "set_AA_scaled = pd.DataFrame(set_AA_scaled, columns = set_AA.columns)\n",
    "na_loc = set_AA_scaled.isnull()\n",
    "set_AA_scaled[na_loc] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_imputed = kernel.impute_new_data(new_data=set_AA_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e02ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_AA_MF_IMP = new_data_imputed.complete_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf90e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_AA_MF_IMP = pd.DataFrame(scaler.inverse_transform(set_AA_MF_IMP),columns=set_AA.columns)\n",
    "\n",
    "# Validation\n",
    "\n",
    "GS_scores(set_AA_MF_IMP,'MF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f1cfdb",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12590d79",
   "metadata": {},
   "source": [
    "### 1) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f649f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f68c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "df_scaled = pd.DataFrame(df_scaled, columns = df.columns)\n",
    "na_loc = df_scaled.isnull()\n",
    "df_scaled[na_loc] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c1e622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn=KNNImputer(n_neighbors=4)\n",
    "\n",
    "knn_=knn.fit_transform(df_scaled)\n",
    "\n",
    "KNN_Imp=pd.DataFrame(scaler.inverse_transform(knn_), columns=df.columns)\n",
    "\n",
    "# Validation\n",
    "\n",
    "LOOCV_scores(KNN_Imp,'KNN')\n",
    "\n",
    "real_pred(KNN_Imp,'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c9223b",
   "metadata": {},
   "source": [
    "### 2) Imputation of the actual missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa0fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_AA_scaled=scaler.fit_transform(set_AA)\n",
    "set_AA_scaled = pd.DataFrame(set_AA_scaled, columns = set_AA.columns)\n",
    "na_loc = set_AA_scaled.isnull()\n",
    "set_AA_scaled[na_loc] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd15232",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_AA_KNN_IMP=knn.transform(set_AA_scaled)\n",
    "\n",
    "set_AA_KNN_IMP=pd.DataFrame(scaler.inverse_transform(set_AA_KNN_IMP), columns=set_AA.columns)\n",
    "\n",
    "# Validation\n",
    "\n",
    "GS_scores(set_AA_KNN_IMP,'KNN' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e0c41",
   "metadata": {},
   "source": [
    "## MIDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4235ea12",
   "metadata": {},
   "source": [
    "### 1) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import MIDASpy as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "df_scaled = pd.DataFrame(df_scaled, columns = df.columns)\n",
    "na_loc = df_scaled.isnull()\n",
    "df_scaled[na_loc] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6276b31d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputer = md.Midas(layer_structure = [256,256], vae_layer = False, seed = 89,input_drop = 0.75)\n",
    "imputer.build_model(df_scaled)\n",
    "imputer.train_model(training_epochs = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ac84ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputations = imputer.generate_samples(m=40).output_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a4a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_dfs = []\n",
    "i=0\n",
    "for imp in imputations:\n",
    "    df_unscaled= scaler.inverse_transform(imputations[i])\n",
    "    df_unscaled= pd.DataFrame(df_unscaled, columns = df_scaled.columns)\n",
    "    imputation_dfs.append(df_unscaled)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1\n",
    "for i in imputation_dfs:\n",
    "    file_out = \"midas_imp_\" + str(n) + \".xlsx\"\n",
    "    i.to_excel(file_out, index=False)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"midas_imp_\"\n",
    "file_names= [path + str(i) + '.xlsx' for i in range(1, 41)]\n",
    "data_all = pd.concat((pd.read_excel(i) for i in file_names), axis=1) # Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc92ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIDAS_Imp=data_all.mean(axis=1, level=0)\n",
    "\n",
    "# Validation\n",
    "\n",
    "LOOCV_scores(MIDAS_Imp,'MIDAS')\n",
    "\n",
    "real_pred(MIDAS_Imp,'MIDAS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bd9b1f",
   "metadata": {},
   "source": [
    "### 2) Imputation of the actual missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c29b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_AA_scaled=scaler.fit_transform(set_AA)\n",
    "set_AA_scaled = pd.DataFrame(set_AA_scaled, columns = set_AA.columns)\n",
    "na_loc = set_AA_scaled.isnull()\n",
    "set_AA_scaled[na_loc] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d549fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputer.build_model(set_AA_scaled)\n",
    "imputer.train_model(training_epochs = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ca103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputations = imputer.generate_samples(m=40).output_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb238f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation_dfs = []\n",
    "i=0\n",
    "for imp in imputations:\n",
    "    df_unscaled= scaler.inverse_transform(imputations[i])\n",
    "    df_unscaled= pd.DataFrame(df_unscaled, columns = df_scaled.columns)\n",
    "    imputation_dfs.append(df_unscaled)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e3d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1\n",
    "for i in imputation_dfs:\n",
    "    file_out = \"midas_imp_\" + str(n) + \".xlsx\"\n",
    "    i.to_excel(file_out, index=False)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196e766",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"midas_imp_\"\n",
    "file_names= [path + str(i) + '.xlsx' for i in range(1, 41)]\n",
    "data_all = pd.concat((pd.read_excel(i) for i in file_names), axis=1) # Import\n",
    "set_AA_MIDAS_IMP=data_all.mean(axis=1, level=0)\n",
    "\n",
    "# Validation\n",
    "\n",
    "GS_scores(set_AA_MIDAS_IMP,'MIDAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c9713d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
