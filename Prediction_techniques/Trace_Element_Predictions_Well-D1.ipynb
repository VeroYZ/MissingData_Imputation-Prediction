{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dc57d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder,StandardScaler\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.compose import make_column_transformer\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92375ec",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131d755b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TEST_5=pd.read_excel(\"TEST-5.xlsx\")\n",
    "Well_D1=pd.read_excel(\"well_D1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae1ed4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Well_D1=Well_D1.drop(['LOI','V', 'Ni', 'Cu', 'Zn', 'Sr', 'Zr', 'Ba'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b15b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "Well_D1.loc[:,'Mo'] = Well_D1.loc[:,'Mo'].mul(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac33fb6a",
   "metadata": {},
   "source": [
    "### Categorical features to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87425393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encoder(test):\n",
    "    well_encoder = OrdinalEncoder(categories=[test['WELL'].unique()])\n",
    "\n",
    "    well_encoder.fit(test[[\"WELL\"]])\n",
    "    test[\"Well\"] = well_encoder.transform(test[[\"WELL\"]])\n",
    "    test.drop('WELL', axis=1, inplace= True)\n",
    "    \n",
    "    Well_D1[\"Well\"] = test['Well'].nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a4578bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder(TEST_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53302193",
   "metadata": {},
   "outputs": [],
   "source": [
    "D1_depth=Well_D1.loc[:,'Depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f61fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_values=TEST_5.drop(['MnO','SO3', 'Ga', 'Nb', 'Pb', 'Rb', 'Th', 'U', 'Y', 'Cr', 'Ba','Sr','Cu','Ni','V', 'Zn', 'Zr'], axis=1)\n",
    "y_values=TEST_5.drop(['Depth','Al2O3', 'SiO2', 'TiO2', 'Fe2O3', 'MgO', 'CaO', 'Na2O', 'K2O','P2O5','Mo','Well'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e035fa81",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebc8bfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': None, 'max_features': 10, 'n_estimators': 30} : -0.009763551535815325 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "MnO:\n",
      "RMSE: 0.015635893011635593\n",
      "NRMSE: 0.1145822439662582\n",
      "R2 score: 0.34544439444019115\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 5, 'n_estimators': 70} : -0.721921726960892 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "SO3:\n",
      "RMSE: 0.5624308104156124\n",
      "NRMSE: 0.15902520694640046\n",
      "R2 score: 0.27652257456649687\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 5, 'n_estimators': 70} : -812.047316401264 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Ba:\n",
      "RMSE: 2738.8582934458054\n",
      "NRMSE: 0.11980798734460035\n",
      "R2 score: 0.2067938422772081\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': None, 'max_features': 25, 'n_estimators': 150} : -23.31498449129773 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Cr:\n",
      "RMSE: 11.676243907494838\n",
      "NRMSE: 0.0856538637073824\n",
      "R2 score: 0.8538198771079871\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 10, 'n_estimators': 150} : -6.966712758091031 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Cu:\n",
      "RMSE: 4.8345190562828\n",
      "NRMSE: 0.11944451309184775\n",
      "R2 score: 0.7866197019513756\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 20, 'max_features': 5, 'n_estimators': 150} : -1.891911196314652 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Ga:\n",
      "RMSE: 1.620712465927848\n",
      "NRMSE: 0.08277049282602592\n",
      "R2 score: 0.7620656250440345\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 10, 'n_estimators': 150} : -0.9614024089223886 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Nb:\n",
      "RMSE: 0.570893641476819\n",
      "NRMSE: 0.06497765097619156\n",
      "R2 score: 0.8665339354965175\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 25, 'n_estimators': 150} : -12.414990964729007 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Ni:\n",
      "RMSE: 7.539856829332681\n",
      "NRMSE: 0.03898125281162888\n",
      "R2 score: 0.9729611763492357\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 5, 'n_estimators': 150} : -14.485828064992711 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Pb:\n",
      "RMSE: 10.298196625510494\n",
      "NRMSE: 0.09084741362413913\n",
      "R2 score: 0.7759960075133523\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 10, 'n_estimators': 150} : -7.257192718227614 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Rb:\n",
      "RMSE: 7.833706496712244\n",
      "NRMSE: 0.08848458314352123\n",
      "R2 score: 0.804854332073041\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 5, 'n_estimators': 150} : -210.25305071942336 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Sr:\n",
      "RMSE: 299.8626216029061\n",
      "NRMSE: 0.13068553898353377\n",
      "R2 score: 0.3607062035959423\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 25, 'n_estimators': 30} : -1.6167225136900234 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Th:\n",
      "RMSE: 1.5473362157820894\n",
      "NRMSE: 0.10952344055253005\n",
      "R2 score: 0.5197514421945192\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': None, 'max_features': 5, 'n_estimators': 70} : -2.520716920664225 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "U:\n",
      "RMSE: 2.0920656910873574\n",
      "NRMSE: 0.12629418443728757\n",
      "R2 score: 0.7749210256782795\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 25, 'n_estimators': 150} : -70.638888651861 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "V:\n",
      "RMSE: 44.389929445056424\n",
      "NRMSE: 0.08356695239943603\n",
      "R2 score: 0.846142220961837\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 10, 'n_estimators': 30} : -2.417031736081919 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Y:\n",
      "RMSE: 1.2662061290972058\n",
      "NRMSE: 0.07034478494984477\n",
      "R2 score: 0.9105522609362476\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 20, 'max_features': 5, 'n_estimators': 150} : -71.8564436408561 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Zn:\n",
      "RMSE: 107.15003762469215\n",
      "NRMSE: 0.14379491687825405\n",
      "R2 score: 0.34199368847640477\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': None, 'max_features': 5, 'n_estimators': 30} : -11.877393183132533 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Zr:\n",
      "RMSE: 7.26210057386733\n",
      "NRMSE: 0.07925426257360772\n",
      "R2 score: 0.8706865562484589\n",
      "\n",
      "\n",
      "\n",
      "Well test validation\n",
      "   y_hat      rmse_RF  nrmse_RF     R2_RF\n",
      "0    MnO     0.015636  0.114582  0.345444\n",
      "1    SO3     0.562431  0.159025  0.276523\n",
      "2     Ba  2738.858293  0.119808  0.206794\n",
      "3     Cr    11.676244  0.085654  0.853820\n",
      "4     Cu     4.834519  0.119445  0.786620\n",
      "5     Ga     1.620712  0.082770  0.762066\n",
      "6     Nb     0.570894  0.064978  0.866534\n",
      "7     Ni     7.539857  0.038981  0.972961\n",
      "8     Pb    10.298197  0.090847  0.775996\n",
      "9     Rb     7.833706  0.088485  0.804854\n",
      "10    Sr   299.862622  0.130686  0.360706\n",
      "11    Th     1.547336  0.109523  0.519751\n",
      "12     U     2.092066  0.126294  0.774921\n",
      "13     V    44.389929  0.083567  0.846142\n",
      "14     Y     1.266206  0.070345  0.910552\n",
      "15    Zn   107.150038  0.143795  0.341994\n",
      "16    Zr     7.262101  0.079254  0.870687\n"
     ]
    }
   ],
   "source": [
    "wells_scores = pd.DataFrame()\n",
    "pred = pd.DataFrame(D1_depth)\n",
    "        \n",
    "for col in y_values:\n",
    "    X = X_values\n",
    "    y = y_values[col]\n",
    "        \n",
    "                \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X,\n",
    "                                        y,\n",
    "                                        train_size   = 0.7,\n",
    "                                        random_state = 123,\n",
    "                                        shuffle      = True\n",
    "                                    )        \n",
    "    \n",
    "    # Evaluated Hyperparameters\n",
    "    \n",
    "    param_grid = {'n_estimators': [30,70,150],\n",
    "                    'max_features': [5, 10, 25],\n",
    "                    'max_depth'   : [None, 3, 10, 20]\n",
    "                    }\n",
    "\n",
    "    # Grid\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "            estimator  = RandomForestRegressor(random_state = 123),\n",
    "            param_grid = param_grid,\n",
    "            scoring    = 'neg_root_mean_squared_error',\n",
    "            n_jobs     = - 1,\n",
    "            cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "            refit      = True,\n",
    "            verbose    = 0,\n",
    "            return_train_score = True\n",
    "            )\n",
    "\n",
    "    grid.fit(X = X_train, y = y_train)\n",
    "\n",
    "    print(\"Final model best hyperparameters: \")        \n",
    "    print(\"\")       \n",
    "    print(grid.best_params_, \":\", grid.best_score_, grid.scoring)\n",
    "    print(\"\")\n",
    "    \n",
    "    # Test scores\n",
    "        \n",
    "    final_model = grid.best_estimator_\n",
    "    predictions = final_model.predict(X = X_test)\n",
    "        \n",
    "    rmse = mean_squared_error(\n",
    "            y_true  = y_test,\n",
    "            y_pred  = predictions,\n",
    "            squared = False\n",
    "            )\n",
    "                \n",
    "    nrmse = rmse/(y_test.max()-y_test.min())\n",
    "        \n",
    "    R2 = r2_score(y_test, predictions)        \n",
    "        \n",
    "    print(\"Wells Test Scores\")\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"NRMSE: {nrmse}\")        \n",
    "    print(f\"R2 score: {R2}\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "        \n",
    "                  \n",
    "    # Save well test validation\n",
    "                \n",
    "    wells_scores = wells_scores.append({\"y_hat\": col, f\"rmse_RF\": rmse, f\"nrmse_RF\": nrmse, f\"R2_RF\": R2}, ignore_index=True)\n",
    "                \n",
    "    wells_scores.to_excel(f\"Wells_TE_scores_RF_D1.xlsx\")         \n",
    "    \n",
    "        \n",
    "    # WELL D1 MAYOR ELEMENTS PREDICTIONS \n",
    "                \n",
    "    X_test_D1 = Well_D1\n",
    "    y_test_D1 = y_values[col]\n",
    "    \n",
    "    D1_predictions = final_model.predict(X_test_D1) \n",
    "    \n",
    "                   \n",
    "    # Save D1 predicted curves\n",
    "        \n",
    "    D1_pred = pd.DataFrame()\n",
    "\n",
    "    D1_pred = D1_pred.assign(Predictions = D1_predictions.flatten().tolist())        \n",
    "                \n",
    "    pred=pd.concat([pred,D1_pred],axis=1)\n",
    "        \n",
    "    pred.columns=pred.columns.str.replace('Predictions', f\"{col}\")\n",
    "        \n",
    "    pred.to_excel(f\"D1_TE_pred_RF.xlsx\")       \n",
    "              \n",
    "    print(\"\")\n",
    "                \n",
    "print(f\"Well test validation\")\n",
    "print(wells_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c97c214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59d1286e",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b40ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col= ['Well']\n",
    "categorical = ['c' if col in cat_col else 'q' for col in X_values.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c514982e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1} : -0.010037834485993274 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 40\n",
      "\n",
      "Wells Test Scores\n",
      "MnO:\n",
      "RMSE: 0.013998528627614255\n",
      "NRMSE: 0.10258338434423461\n",
      "R2 score: 0.4753545076859823\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 3, 'subsample': 1} : -0.7894856718622097 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 418\n",
      "\n",
      "Wells Test Scores\n",
      "SO3:\n",
      "RMSE: 0.22488469609905262\n",
      "NRMSE: 0.06358530627047863\n",
      "R2 score: 0.884333769981063\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 0.5} : -813.6876459004519 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 23\n",
      "\n",
      "Wells Test Scores\n",
      "Ba:\n",
      "RMSE: 2987.285203235777\n",
      "NRMSE: 0.1306751169567458\n",
      "R2 score: 0.056373069374873075\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 5, 'subsample': 1} : -21.95612123265848 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 232\n",
      "\n",
      "Wells Test Scores\n",
      "Cr:\n",
      "RMSE: 12.944433026498519\n",
      "NRMSE: 0.09495696655577368\n",
      "R2 score: 0.8203413750593264\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 1, 'subsample': 0.5} : -7.069177146100518 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 46\n",
      "\n",
      "Wells Test Scores\n",
      "Cu:\n",
      "RMSE: 5.428462204127417\n",
      "NRMSE: 0.13411882697346206\n",
      "R2 score: 0.7309695727685994\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 20, 'subsample': 1} : -1.9655918336259195 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 414\n",
      "\n",
      "Wells Test Scores\n",
      "Ga:\n",
      "RMSE: 1.712251492444513\n",
      "NRMSE: 0.0874454308529025\n",
      "R2 score: 0.7344291816423318\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1} : -1.0034905051535843 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 23\n",
      "\n",
      "Wells Test Scores\n",
      "Nb:\n",
      "RMSE: 0.7789069704050758\n",
      "NRMSE: 0.08865319490155656\n",
      "R2 score: 0.7515542205164928\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 1, 'subsample': 1} : -14.272840943457496 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 80\n",
      "\n",
      "Wells Test Scores\n",
      "Ni:\n",
      "RMSE: 9.19965573077586\n",
      "NRMSE: 0.04756245561934146\n",
      "R2 score: 0.9597463982478\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 3, 'subsample': 1} : -15.977480419048042 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 62\n",
      "\n",
      "Wells Test Scores\n",
      "Pb:\n",
      "RMSE: 15.87138818598298\n",
      "NRMSE: 0.14001233611615913\n",
      "R2 score: 0.4679367935572947\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1} : -7.669172520000282 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 29\n",
      "\n",
      "Wells Test Scores\n",
      "Rb:\n",
      "RMSE: 8.998242607276227\n",
      "NRMSE: 0.1016384449000318\n",
      "R2 score: 0.742522241641032\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 20, 'subsample': 0.5} : -213.6463129448825 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 19\n",
      "\n",
      "Wells Test Scores\n",
      "Sr:\n",
      "RMSE: 306.7041832502691\n",
      "NRMSE: 0.13366721494766484\n",
      "R2 score: 0.33120160524546116\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 3, 'subsample': 1} : -1.8551375853941359 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 200\n",
      "\n",
      "Wells Test Scores\n",
      "Th:\n",
      "RMSE: 1.5329705610833713\n",
      "NRMSE: 0.10850661181657367\n",
      "R2 score: 0.5286274174551953\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5} : -2.754536542085738 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 38\n",
      "\n",
      "Wells Test Scores\n",
      "U:\n",
      "RMSE: 2.1772019725741756\n",
      "NRMSE: 0.13143370624207973\n",
      "R2 score: 0.7562291727923633\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 5, 'subsample': 0.5} : -73.62934394021983 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 28\n",
      "\n",
      "Wells Test Scores\n",
      "V:\n",
      "RMSE: 44.87914302018225\n",
      "NRMSE: 0.08448792902762146\n",
      "R2 score: 0.8427322547825106\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 5, 'subsample': 0.5} : -2.6387494245808174 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 214\n",
      "\n",
      "Wells Test Scores\n",
      "Y:\n",
      "RMSE: 1.6830506612466216\n",
      "NRMSE: 0.0935028145137012\n",
      "R2 score: 0.8419644026476822\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5} : -73.68973049665952 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 39\n",
      "\n",
      "Wells Test Scores\n",
      "Zn:\n",
      "RMSE: 107.47641015570171\n",
      "NRMSE: 0.1442329074941066\n",
      "R2 score: 0.3379790888415366\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 1, 'subsample': 1} : -12.435223504843774 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 81\n",
      "\n",
      "Wells Test Scores\n",
      "Zr:\n",
      "RMSE: 7.278734413391138\n",
      "NRMSE: 0.07943579444194498\n",
      "R2 score: 0.8700934929995436\n",
      "\n",
      "\n",
      "\n",
      "Well test validation\n",
      "   y_hat     rmse_XGB  nrmse_XGB    R2_XGB\n",
      "0    MnO     0.013999   0.102583  0.475355\n",
      "1    SO3     0.224885   0.063585  0.884334\n",
      "2     Ba  2987.285203   0.130675  0.056373\n",
      "3     Cr    12.944433   0.094957  0.820341\n",
      "4     Cu     5.428462   0.134119  0.730970\n",
      "5     Ga     1.712251   0.087445  0.734429\n",
      "6     Nb     0.778907   0.088653  0.751554\n",
      "7     Ni     9.199656   0.047562  0.959746\n",
      "8     Pb    15.871388   0.140012  0.467937\n",
      "9     Rb     8.998243   0.101638  0.742522\n",
      "10    Sr   306.704183   0.133667  0.331202\n",
      "11    Th     1.532971   0.108507  0.528627\n",
      "12     U     2.177202   0.131434  0.756229\n",
      "13     V    44.879143   0.084488  0.842732\n",
      "14     Y     1.683051   0.093503  0.841964\n",
      "15    Zn   107.476410   0.144233  0.337979\n",
      "16    Zr     7.278734   0.079436  0.870093\n"
     ]
    }
   ],
   "source": [
    "wells_scores = pd.DataFrame()\n",
    "pred = pd.DataFrame(D1_depth)\n",
    "        \n",
    "for col in y_values:\n",
    "    X = X_values\n",
    "    y = y_values[col]\n",
    "        \n",
    "                \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X,\n",
    "                                        y,\n",
    "                                        train_size   = 0.7,\n",
    "                                        random_state = 123,\n",
    "                                        shuffle      = True\n",
    "                                    )        \n",
    "    \n",
    "    # Evaluated Hyperparameters    \n",
    "    \n",
    "    param_grid = {'max_depth'        : [None, 1, 3, 5, 10, 20],\n",
    "                  'subsample'        : [0.5, 1],\n",
    "                  'learning_rate'    : [0.001, 0.01, 0.1],\n",
    "                  'booster'          : ['gbtree']\n",
    "                 }\n",
    "\n",
    "\n",
    "    # Creation of validation set\n",
    "    \n",
    "    np.random.seed(123)\n",
    "    idx_validacion = np.random.choice(\n",
    "                        X_train.shape[0],\n",
    "                        size=int(X_train.shape[0]*0.1), \n",
    "                        replace=False\n",
    "                        )\n",
    "\n",
    "    X_val = X_train.iloc[idx_validacion, :].copy()\n",
    "    y_val = y_train.iloc[idx_validacion].copy()\n",
    "\n",
    "    X_train_grid = X_train.reset_index(drop = True).drop(idx_validacion, axis = 0).copy()\n",
    "    y_train_grid = y_train.reset_index(drop = True).drop(idx_validacion, axis = 0).copy()\n",
    "\n",
    "        \n",
    "    fit_params = {\"eval_set\": [(X_val, y_val)],\n",
    "                   \"verbose\": False\n",
    "                    }\n",
    "\n",
    "    # Grid\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "            estimator  = XGBRegressor(\n",
    "                            n_estimators          = 1000,\n",
    "                            early_stopping_rounds = 5,\n",
    "                            eval_metric           = \"rmse\",\n",
    "                            tree_method           ='hist',\n",
    "                            enable_categorical    =True,\n",
    "                            random_state          = 123,\n",
    "                            feature_types         = categorical,\n",
    "                        ),\n",
    "            param_grid = param_grid,\n",
    "            scoring    = 'neg_root_mean_squared_error',\n",
    "            n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "            cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n",
    "            refit      = True,\n",
    "            verbose    = 0,\n",
    "            return_train_score = True\n",
    "            )\n",
    "\n",
    "    grid.fit(X = X_train_grid, y = y_train_grid, **fit_params)\n",
    "\n",
    "    print(\"Final model best hyperparameters: \")        \n",
    "    print(\"\")       \n",
    "    print(grid.best_params_, \":\", grid.best_score_, grid.scoring)\n",
    "    print(\"\")\n",
    "    n_trees_incluid = len(grid.best_estimator_.get_booster().get_dump())\n",
    "    print(f\"Final trees early stopping: {n_trees_incluid}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Test scores       \n",
    "    \n",
    "    final_model = grid.best_estimator_\n",
    "    predictions = final_model.predict(X_test)\n",
    "        \n",
    "    rmse = mean_squared_error(\n",
    "            y_true  = y_test,\n",
    "            y_pred  = predictions,\n",
    "            squared = False\n",
    "               )\n",
    "                \n",
    "    nrmse = rmse/(y_test.max()-y_test.min())\n",
    "        \n",
    "    R2 = r2_score(y_test, predictions)        \n",
    "        \n",
    "    print(\"Wells Test Scores\")\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"NRMSE: {nrmse}\")        \n",
    "    print(f\"R2 score: {R2}\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Save well test validation\n",
    "                \n",
    "    wells_scores = wells_scores.append({\"y_hat\":col,f\"rmse_XGB\": rmse, f\"nrmse_XGB\": nrmse, f\"R2_XGB\": R2}, ignore_index=True)\n",
    "                \n",
    "    wells_scores.to_excel(f\"Wells_TE_scores_XGB_D1.xlsx\") \n",
    "        \n",
    "    \n",
    "    # WELL D1 MAYOR ELEMENTS PREDICTIONS \n",
    "                \n",
    "    X_test_D1 = Well_D1\n",
    "    y_test_D1 = y_values[col]\n",
    "    \n",
    "    D1_predictions = final_model.predict(X_test_D1) \n",
    "    \n",
    "       \n",
    "    # Save D1 predicted curves\n",
    "        \n",
    "    D1_pred = pd.DataFrame()\n",
    "\n",
    "    D1_pred = D1_pred.assign(Predictions = D1_predictions.flatten().tolist())        \n",
    "                \n",
    "    pred = pd.concat([pred,D1_pred],axis=1)\n",
    "        \n",
    "    pred.columns = pred.columns.str.replace('Predictions', f\"{col}\")\n",
    "        \n",
    "    pred.to_excel(f\"D1_TE_pred_XGB.xlsx\")  \n",
    "    \n",
    "    print(\"\")\n",
    "                \n",
    "print(f\"Well test validation\")\n",
    "print(wells_scores)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc581c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb19bce7",
   "metadata": {},
   "source": [
    "## Gradient Boosting: HistGradientBoostingregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "425a50d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_values['Well']=X_values['Well'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aa39171",
   "metadata": {},
   "outputs": [],
   "source": [
    "Well_D1_=Well_D1.copy()\n",
    "\n",
    "cols = list(Well_D1_.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "Well_D1_ = Well_D1_[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d29f3cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 0, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -0.01212398886682049 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 121\n",
      "\n",
      "Wells Test Scores\n",
      "MnO:\n",
      "RMSE: 0.015286247094842309\n",
      "NRMSE: 0.11201998457307863\n",
      "R2 score: 0.3743911018073669\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 10, 'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3} : -0.850907560407022 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 403\n",
      "\n",
      "Wells Test Scores\n",
      "SO3:\n",
      "RMSE: 0.4113019656629128\n",
      "NRMSE: 0.11629409163888577\n",
      "R2 score: 0.613091431959201\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 0, 'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 3} : -938.4018712746971 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 41\n",
      "\n",
      "Wells Test Scores\n",
      "Ba:\n",
      "RMSE: 2918.063911970173\n",
      "NRMSE: 0.12764711671015677\n",
      "R2 score: 0.09959779303575844\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 0, 'learning_rate': 0.01, 'loss': 'squared_error', 'max_depth': 3} : -29.66724324402092 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 341\n",
      "\n",
      "Wells Test Scores\n",
      "Cr:\n",
      "RMSE: 15.666694397005385\n",
      "NRMSE: 0.11492676217263269\n",
      "R2 score: 0.7368297763484641\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 1, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -6.788401585160879 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 18\n",
      "\n",
      "Wells Test Scores\n",
      "Cu:\n",
      "RMSE: 5.933288021844242\n",
      "NRMSE: 0.14659135491086212\n",
      "R2 score: 0.6786053623216497\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 1, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -2.191851919594917 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 41\n",
      "\n",
      "Wells Test Scores\n",
      "Ga:\n",
      "RMSE: 1.998030173282438\n",
      "NRMSE: 0.10204027278162477\n",
      "R2 score: 0.6383825911911392\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 0, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -1.1858094422983563 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 38\n",
      "\n",
      "Wells Test Scores\n",
      "Nb:\n",
      "RMSE: 0.6559751115902297\n",
      "NRMSE: 0.07466140582634073\n",
      "R2 score: 0.823788127187851\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 1, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -25.18481748390954 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 44\n",
      "\n",
      "Wells Test Scores\n",
      "Ni:\n",
      "RMSE: 12.704398351889942\n",
      "NRMSE: 0.06568206468430966\n",
      "R2 score: 0.9232338429463407\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 0, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -18.29565950865059 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 96\n",
      "\n",
      "Wells Test Scores\n",
      "Pb:\n",
      "RMSE: 11.35809005565297\n",
      "NRMSE: 0.10019745619442147\n",
      "R2 score: 0.7275141119482769\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 0, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -8.60197112624874 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 71\n",
      "\n",
      "Wells Test Scores\n",
      "Rb:\n",
      "RMSE: 8.812813436226973\n",
      "NRMSE: 0.09954395451928698\n",
      "R2 score: 0.7530247261564322\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 10, 'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 3} : -248.22283345541686 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 84\n",
      "\n",
      "Wells Test Scores\n",
      "Sr:\n",
      "RMSE: 319.50580647154504\n",
      "NRMSE: 0.13924639324469187\n",
      "R2 score: 0.2742060675251412\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 0, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -1.900287527938578 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 19\n",
      "\n",
      "Wells Test Scores\n",
      "Th:\n",
      "RMSE: 1.618015926638158\n",
      "NRMSE: 0.11452628675444744\n",
      "R2 score: 0.4748755098540599\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 1, 'learning_rate': 0.01, 'loss': 'absolute_error', 'max_depth': 3} : -3.0876442057689872 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 586\n",
      "\n",
      "Wells Test Scores\n",
      "U:\n",
      "RMSE: 2.3004815231124156\n",
      "NRMSE: 0.1388758675276224\n",
      "R2 score: 0.7278415695022737\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 0, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -86.5110995646116 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 17\n",
      "\n",
      "Wells Test Scores\n",
      "V:\n",
      "RMSE: 59.63278143478594\n",
      "NRMSE: 0.1122626205967468\n",
      "R2 score: 0.7223352923962367\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 1, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -2.776176095352239 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 35\n",
      "\n",
      "Wells Test Scores\n",
      "Y:\n",
      "RMSE: 1.7280404780831975\n",
      "NRMSE: 0.09600224878239987\n",
      "R2 score: 0.8334025432209271\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 1, 'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 3} : -70.50952427179702 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 40\n",
      "\n",
      "Wells Test Scores\n",
      "Zn:\n",
      "RMSE: 116.7275952239434\n",
      "NRMSE: 0.15664796041805074\n",
      "R2 score: 0.21910529057071904\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 1, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -13.834928496252422 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 39\n",
      "\n",
      "Wells Test Scores\n",
      "Zr:\n",
      "RMSE: 8.884865687612528\n",
      "NRMSE: 0.09696415947077537\n",
      "R2 score: 0.8064376469181109\n",
      "\n",
      "\n",
      "\n",
      "Well test validation\n",
      "   y_hat    rmse_HGBT  nrmse_HGBT   R2_HGBT\n",
      "0    MnO     0.015286    0.112020  0.374391\n",
      "1    SO3     0.411302    0.116294  0.613091\n",
      "2     Ba  2918.063912    0.127647  0.099598\n",
      "3     Cr    15.666694    0.114927  0.736830\n",
      "4     Cu     5.933288    0.146591  0.678605\n",
      "5     Ga     1.998030    0.102040  0.638383\n",
      "6     Nb     0.655975    0.074661  0.823788\n",
      "7     Ni    12.704398    0.065682  0.923234\n",
      "8     Pb    11.358090    0.100197  0.727514\n",
      "9     Rb     8.812813    0.099544  0.753025\n",
      "10    Sr   319.505806    0.139246  0.274206\n",
      "11    Th     1.618016    0.114526  0.474876\n",
      "12     U     2.300482    0.138876  0.727842\n",
      "13     V    59.632781    0.112263  0.722335\n",
      "14     Y     1.728040    0.096002  0.833403\n",
      "15    Zn   116.727595    0.156648  0.219105\n",
      "16    Zr     8.884866    0.096964  0.806438\n"
     ]
    }
   ],
   "source": [
    "wells_scores = pd.DataFrame()\n",
    "pred = pd.DataFrame(D1_depth)\n",
    "        \n",
    "for col in y_values:\n",
    "    X = X_values\n",
    "    y = y_values[col]\n",
    "        \n",
    "                \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X,\n",
    "                                        y,\n",
    "                                        train_size   = 0.7,\n",
    "                                        random_state = 123,\n",
    "                                        shuffle      = True\n",
    "                                    )\n",
    "    \n",
    "    cat_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    \n",
    "    preprocessor = make_column_transformer(\n",
    "                        (\n",
    "                            OrdinalEncoder(\n",
    "                                dtype=int,\n",
    "                                handle_unknown=\"use_encoded_value\",\n",
    "                                unknown_value=-1,\n",
    "                                encoded_missing_value=-1\n",
    "                            ),\n",
    "                            cat_cols\n",
    "                        ),\n",
    "                        remainder=\"passthrough\",\n",
    "                        verbose_feature_names_out=False,\n",
    "                   ).set_output(transform=\"pandas\")\n",
    "        \n",
    "    X_train_prep = preprocessor.fit_transform(X_train)\n",
    "    X_test_prep = preprocessor.transform(X_test)\n",
    "\n",
    "\n",
    "    # Evaluated Hyperparameters\n",
    "    \n",
    "    param_grid = {'loss'             : ['squared_error', 'absolute_error'],\n",
    "                    'learning_rate'    : [0.001, 0.01, 0.1],\n",
    "                    'max_depth'        : [3, 5, 10, 20],\n",
    "                    'l2_regularization': [0, 1, 10]\n",
    "                    }\n",
    "\n",
    "    # Grid\n",
    "        \n",
    "    grid = GridSearchCV(\n",
    "            estimator  = HistGradientBoostingRegressor(\n",
    "                            max_iter            = 1000, \n",
    "                            random_state        = 123,\n",
    "                            early_stopping      = True,\n",
    "                            validation_fraction = 0.1,\n",
    "                            n_iter_no_change    = 10,\n",
    "                            tol                 = 1e-7,\n",
    "                            scoring             = 'loss',\n",
    "                            categorical_features = cat_cols\n",
    "                        ),\n",
    "            param_grid = param_grid,\n",
    "            scoring    = 'neg_root_mean_squared_error',\n",
    "            n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "            cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n",
    "            refit      = True,\n",
    "            verbose    = 0,\n",
    "            return_train_score = True\n",
    "            )\n",
    "\n",
    "    grid.fit(X = X_train_prep, y = y_train)\n",
    "        \n",
    "        \n",
    "    print(\"Final model best hyperparameters: \")        \n",
    "    print(\"\")       \n",
    "    print(grid.best_params_, \":\", grid.best_score_, grid.scoring)\n",
    "    print(\"\")        \n",
    "    print(f\"Final trees early stopping: {grid.best_estimator_.n_iter_}\")\n",
    "    print(\"\")    \n",
    "        \n",
    "        \n",
    "    # Test scores\n",
    "    \n",
    "    final_model = grid.best_estimator_\n",
    "    predictions = final_model.predict(X = X_test_prep)\n",
    "    \n",
    "    rmse = mean_squared_error(\n",
    "            y_true  = y_test,\n",
    "            y_pred  = predictions,\n",
    "            squared = False\n",
    "           )\n",
    "        \n",
    "    nrmse = rmse/(y_test.max()-y_test.min())\n",
    "        \n",
    "    R2 = r2_score(y_test, predictions)        \n",
    "        \n",
    "    print(\"Wells Test Scores\")\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"NRMSE: {nrmse}\")        \n",
    "    print(f\"R2 score: {R2}\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "        \n",
    "                  \n",
    "    # Save well test validation\n",
    "        \n",
    "    wells_scores = wells_scores.append({\"y_hat\":col,f\"rmse_HGBT\": rmse, f\"nrmse_HGBT\": nrmse,f\"R2_HGBT\": R2},ignore_index=True)\n",
    "                \n",
    "    wells_scores.to_excel(f\"Wells_TE_scores_HGBT_D1.xlsx\")  \n",
    "    \n",
    "           \n",
    "    # WELL D1 MAYOR ELEMENTS PREDICTIONS \n",
    "                \n",
    "    X_test_D1 = Well_D1_\n",
    "    y_test_D1 = y_values[col]\n",
    "        \n",
    "    D1_predictions = final_model.predict(X_test_D1) \n",
    "    \n",
    "    # Save D1 predicted curves\n",
    "        \n",
    "    D1_pred = pd.DataFrame()\n",
    "\n",
    "    D1_pred = D1_pred.assign(Predictions = D1_predictions.flatten().tolist())        \n",
    "                \n",
    "    pred = pd.concat([pred,D1_pred],axis=1)\n",
    "        \n",
    "    pred.columns = pred.columns.str.replace('Predictions', f\"{col}\")\n",
    "        \n",
    "    pred.to_excel(f\"D1_TE_pred_HGBT.xlsx\")        \n",
    "    \n",
    "    print(\"\")\n",
    "        \n",
    "print(f\"Well test validation\")\n",
    "print(wells_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef73f21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f29f9d8",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d80dbbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Well_D1['Well']=Well_D1['Well'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7433db52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.01, 'max_depth': -1, 'n_estimators': 1000, 'subsample': 0.5} : -0.011965929500605703 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "MnO:\n",
      "RMSE: 0.014392898584478576\n",
      "NRMSE: 0.10547338842502255\n",
      "R2 score: 0.445377228415334\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 100, 'subsample': 0.5} : -0.7897639277009029 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "SO3:\n",
      "RMSE: 0.3551458728524035\n",
      "NRMSE: 0.10041616654105293\n",
      "R2 score: 0.7115302213393639\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.01, 'max_depth': -1, 'n_estimators': 500, 'subsample': 0.5} : -942.5881938866818 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Ba:\n",
      "RMSE: 2732.9669611632517\n",
      "NRMSE: 0.1195502782600376\n",
      "R2 score: 0.2102025729575886\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.001, 'max_depth': -1, 'n_estimators': 5000, 'subsample': 0.5} : -26.883083979559785 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Cr:\n",
      "RMSE: 13.510855564856787\n",
      "NRMSE: 0.09911209377696736\n",
      "R2 score: 0.8042743661291467\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.001, 'max_depth': -1, 'n_estimators': 5000, 'subsample': 0.5} : -6.920728453616932 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Cu:\n",
      "RMSE: 5.157884408169468\n",
      "NRMSE: 0.12743377046310214\n",
      "R2 score: 0.7571204359599059\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 500, 'subsample': 0.5} : -2.0024729345615584 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Ga:\n",
      "RMSE: 1.6774567183595706\n",
      "NRMSE: 0.08566844655783068\n",
      "R2 score: 0.7451128791073396\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 5000, 'subsample': 0.5} : -1.1007943623403242 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Nb:\n",
      "RMSE: 0.6632828572216136\n",
      "NRMSE: 0.07549315470312015\n",
      "R2 score: 0.8198401594870341\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 500, 'subsample': 0.5} : -21.476097367855825 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Ni:\n",
      "RMSE: 12.913681401418357\n",
      "NRMSE: 0.06676406340756365\n",
      "R2 score: 0.9206838309538508\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 100, 'subsample': 0.5} : -17.19683628970787 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Pb:\n",
      "RMSE: 13.226595461089367\n",
      "NRMSE: 0.11668081630099796\n",
      "R2 score: 0.6304871539629808\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 500, 'subsample': 0.5} : -7.913475662939967 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Rb:\n",
      "RMSE: 8.901752942279348\n",
      "NRMSE: 0.10054855880479832\n",
      "R2 score: 0.7480145896125883\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 100, 'subsample': 0.5} : -251.0038531007282 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Sr:\n",
      "RMSE: 292.224152287817\n",
      "NRMSE: 0.12735655628433787\n",
      "R2 score: 0.39286113009532064\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 500, 'subsample': 0.5} : -1.621595566883468 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Th:\n",
      "RMSE: 1.5855090945183696\n",
      "NRMSE: 0.11222539050519678\n",
      "R2 score: 0.49576363483030883\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 100, 'subsample': 0.5} : -2.920927484342298 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "U:\n",
      "RMSE: 2.300022767200986\n",
      "NRMSE: 0.13884817327120558\n",
      "R2 score: 0.7279501049010819\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 1000, 'subsample': 0.5} : -80.500257571335 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "V:\n",
      "RMSE: 56.623264009577674\n",
      "NRMSE: 0.10659700673878963\n",
      "R2 score: 0.7496541766276762\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 100, 'subsample': 0.5} : -2.816271253283741 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Y:\n",
      "RMSE: 1.7244648919827046\n",
      "NRMSE: 0.09580360511015025\n",
      "R2 score: 0.8340912623535556\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.001, 'max_depth': -1, 'n_estimators': 5000, 'subsample': 0.5} : -71.31223978236353 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Zn:\n",
      "RMSE: 108.02408467509179\n",
      "NRMSE: 0.14496788448280237\n",
      "R2 score: 0.3312148924078142\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 1000, 'subsample': 0.5} : -13.587126094390305 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Zr:\n",
      "RMSE: 8.071695451577177\n",
      "NRMSE: 0.0880897013510818\n",
      "R2 score: 0.8402471208511146\n",
      "\n",
      "\n",
      "\n",
      "Well test validation\n",
      "   y_hat    rmse_LGBM  nrmse_LGBM   R2_LGBM\n",
      "0    MnO     0.014393    0.105473  0.445377\n",
      "1    SO3     0.355146    0.100416  0.711530\n",
      "2     Ba  2732.966961    0.119550  0.210203\n",
      "3     Cr    13.510856    0.099112  0.804274\n",
      "4     Cu     5.157884    0.127434  0.757120\n",
      "5     Ga     1.677457    0.085668  0.745113\n",
      "6     Nb     0.663283    0.075493  0.819840\n",
      "7     Ni    12.913681    0.066764  0.920684\n",
      "8     Pb    13.226595    0.116681  0.630487\n",
      "9     Rb     8.901753    0.100549  0.748015\n",
      "10    Sr   292.224152    0.127357  0.392861\n",
      "11    Th     1.585509    0.112225  0.495764\n",
      "12     U     2.300023    0.138848  0.727950\n",
      "13     V    56.623264    0.106597  0.749654\n",
      "14     Y     1.724465    0.095804  0.834091\n",
      "15    Zn   108.024085    0.144968  0.331215\n",
      "16    Zr     8.071695    0.088090  0.840247\n"
     ]
    }
   ],
   "source": [
    "wells_scores = pd.DataFrame()\n",
    "pred = pd.DataFrame(D1_depth)\n",
    "    \n",
    "for col in y_values:\n",
    "    X = X_values\n",
    "    y = y_values[col]\n",
    "        \n",
    "                \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X,\n",
    "                                        y,\n",
    "                                        train_size   = 0.7,\n",
    "                                        random_state = 123,\n",
    "                                        shuffle      = True\n",
    "                                    )        \n",
    "    \n",
    "    # Evaluated Hyperparameters\n",
    "    \n",
    "    param_grid = {'n_estimators'     : [100, 500, 1000, 5000],\n",
    "                  'max_depth'        : [-1, 1, 3, 5, 10, 20],\n",
    "                  'subsample'        : [0.5, 1],\n",
    "                  'learning_rate'    : [0.001, 0.01, 0.1],\n",
    "                  'boosting_type'    : ['gbdt']\n",
    "                     }\n",
    "\n",
    "    # Grid\n",
    "        \n",
    "    grid = GridSearchCV(\n",
    "            estimator  = LGBMRegressor(random_state=123),\n",
    "            param_grid = param_grid,\n",
    "            scoring    = 'neg_root_mean_squared_error',\n",
    "            n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "            cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n",
    "            refit      = True,\n",
    "            verbose    = 0,\n",
    "            return_train_score = True\n",
    "            )\n",
    "\n",
    "    grid.fit(X = X_train, y = y_train, categorical_feature='auto')\n",
    "\n",
    "    print(\"Final model best hyperparameters: \")        \n",
    "    print(\"\")       \n",
    "    print(grid.best_params_, \":\", grid.best_score_, grid.scoring)\n",
    "    print(\"\")\n",
    "    \n",
    "        \n",
    "    # Test scores\n",
    "        \n",
    "    final_model = grid.best_estimator_\n",
    "    predictions = final_model.predict(X = X_test)\n",
    "        \n",
    "    rmse = mean_squared_error(\n",
    "            y_true  = y_test,\n",
    "            y_pred  = predictions,\n",
    "            squared = False\n",
    "            )\n",
    "        \n",
    "    nrmse = rmse/(y_test.max()-y_test.min())\n",
    "        \n",
    "    R2 = r2_score(y_test, predictions)        \n",
    "        \n",
    "    print(\"Wells Test Scores\")\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"NRMSE: {nrmse}\")        \n",
    "    print(f\"R2 score: {R2}\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "        \n",
    "                  \n",
    "    # Save well test validation\n",
    "                \n",
    "    wells_scores = wells_scores.append({\"y_hat\":col,f\"rmse_LGBM\": rmse, f\"nrmse_LGBM\": nrmse, f\"R2_LGBM\": R2}, ignore_index=True)\n",
    "                \n",
    "    wells_scores.to_excel(f\"Wells_TE_scores_LGBM_D1.xlsx\")         \n",
    "    \n",
    "        \n",
    "    # WELL D1 MAYOR ELEMENTS PREDICTIONS\n",
    "    \n",
    "    X_test_D1 = Well_D1\n",
    "    y_test_D1 = y_values[col]\n",
    "    \n",
    "    D1_predictions = final_model.predict(X_test_D1) \n",
    "    \n",
    "    # Save D1 predicted curves\n",
    "        \n",
    "    D1_pred = pd.DataFrame()\n",
    "\n",
    "    D1_pred = D1_pred.assign(Predictions = D1_predictions.flatten().tolist())        \n",
    "                \n",
    "    pred = pd.concat([pred,D1_pred],axis=1)\n",
    "        \n",
    "    pred.columns = pred.columns.str.replace('Predictions', f\"{col}\")\n",
    "        \n",
    "    pred.to_excel(f\"D1_TE_pred_LGBM.xlsx\") \n",
    "        \n",
    "        \n",
    "    print(\"\")\n",
    "        \n",
    "print(f\"Well test validation\")\n",
    "print(wells_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e0d0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f216f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
