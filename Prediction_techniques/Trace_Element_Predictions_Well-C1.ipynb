{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dc57d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder,StandardScaler\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.compose import make_column_transformer\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6558433d",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "131d755b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TEST_3=pd.read_excel(\"TEST-3.xlsx\")\n",
    "Well_C1=pd.read_excel(\"well_C1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21fe80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Well_C1=Well_C1.drop(['WELL','LOI', 'Cr2O3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b15b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_ppm=Well_C1['V2O5'].apply(lambda x: x*0.56016*10000).to_frame().rename(columns={'V2O5':'V'})\n",
    "Well_C1=Well_C1.drop(['V2O5'], axis=1)\n",
    "Well_C1=pd.concat([Well_C1,V_ppm], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1f5dbf",
   "metadata": {},
   "source": [
    "### Categorical features to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62627d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encoder(test):\n",
    "    well_encoder = OrdinalEncoder(categories=[test['WELL'].unique()])\n",
    "\n",
    "    well_encoder.fit(test[[\"WELL\"]])\n",
    "    test[\"Well\"] = well_encoder.transform(test[[\"WELL\"]])\n",
    "    test.drop('WELL', axis=1, inplace= True)\n",
    "    \n",
    "    Well_C1[\"Well\"] = test['Well'].nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e9a90b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder(TEST_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53302193",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_depth=Well_C1.loc[:,'Depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f61fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_values=TEST_3.drop(['SO3', 'Ba', 'Cu', 'Ga', 'Mo', 'Nb', 'Ni','Pb', 'Rb', 'Sr', 'Th', 'U', 'Y', 'Zn', 'Zr','Cr'], axis=1)\n",
    "y_values=TEST_3.drop(['Al2O3', 'SiO2', 'TiO2', 'Fe2O3', 'MnO', 'MgO', 'CaO', 'Na2O', 'K2O','P2O5','V','Depth','Well' ],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e035fa81",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba848607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': None, 'max_features': 10, 'n_estimators': 150} : -0.2558826777346141 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "SO3:\n",
      "RMSE: 0.194669791535667\n",
      "NRMSE: 0.048762656971653905\n",
      "R2 score: 0.9084749118331812\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': None, 'max_features': 5, 'n_estimators': 150} : -1011.7626333278026 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Ba:\n",
      "RMSE: 350.591545634206\n",
      "NRMSE: 0.0646196224202486\n",
      "R2 score: 0.6211485674088422\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': None, 'max_features': 10, 'n_estimators': 30} : -18.619618804735758 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Cr:\n",
      "RMSE: 15.885782278594032\n",
      "NRMSE: 0.0967263371816608\n",
      "R2 score: 0.6990105118090758\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': None, 'max_features': 10, 'n_estimators': 150} : -4.95827883332648 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Cu:\n",
      "RMSE: 4.841711915997591\n",
      "NRMSE: 0.11594690254630408\n",
      "R2 score: 0.7624763591887864\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 20, 'max_features': 5, 'n_estimators': 150} : -1.3448381686041821 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Ga:\n",
      "RMSE: 1.4420865565381422\n",
      "NRMSE: 0.06554938893355192\n",
      "R2 score: 0.8126018276584591\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 10, 'n_estimators': 70} : -14.653681333108834 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Mo:\n",
      "RMSE: 9.549804424585956\n",
      "NRMSE: 0.05159267652396519\n",
      "R2 score: 0.9090765592411156\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 20, 'max_features': 5, 'n_estimators': 150} : -0.657826749728747 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Nb:\n",
      "RMSE: 0.7505347371807466\n",
      "NRMSE: 0.07822494777574675\n",
      "R2 score: 0.7722097229868042\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 5, 'n_estimators': 150} : -16.26065490836517 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Ni:\n",
      "RMSE: 12.4511733716314\n",
      "NRMSE: 0.052259311245347106\n",
      "R2 score: 0.9074087222676219\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 5, 'n_estimators': 150} : -11.74233348055703 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Pb:\n",
      "RMSE: 11.217819633085895\n",
      "NRMSE: 0.10371547030226358\n",
      "R2 score: 0.4456072934699038\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 10, 'n_estimators': 70} : -4.500893988086402 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Rb:\n",
      "RMSE: 4.671054107459268\n",
      "NRMSE: 0.03410098056857429\n",
      "R2 score: 0.9452237720624876\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': None, 'max_features': 5, 'n_estimators': 150} : -162.59084717805555 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Sr:\n",
      "RMSE: 181.14158098485086\n",
      "NRMSE: 0.11686146858620686\n",
      "R2 score: 0.5469425358449599\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 20, 'max_features': 5, 'n_estimators': 150} : -0.9907858551866416 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Th:\n",
      "RMSE: 0.97652905782645\n",
      "NRMSE: 0.06861878727378609\n",
      "R2 score: 0.8043887912072419\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 10, 'n_estimators': 150} : -1.8115720153667991 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "U:\n",
      "RMSE: 1.8109065577530676\n",
      "NRMSE: 0.12520986752742125\n",
      "R2 score: 0.7506514107746114\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 20, 'max_features': 10, 'n_estimators': 150} : -1.8224196735415648 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Y:\n",
      "RMSE: 2.0162711485562257\n",
      "NRMSE: 0.0822967815737235\n",
      "R2 score: 0.8417193313283625\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': 10, 'max_features': 5, 'n_estimators': 150} : -76.85096614620254 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Zn:\n",
      "RMSE: 92.6985016949706\n",
      "NRMSE: 0.12391217745549328\n",
      "R2 score: 0.23794170619246235\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'max_depth': None, 'max_features': 5, 'n_estimators': 150} : -8.844723083328008 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Zr:\n",
      "RMSE: 9.273451678513846\n",
      "NRMSE: 0.06541312324171625\n",
      "R2 score: 0.8829335042618646\n",
      "\n",
      "\n",
      "\n",
      "Well test validation\n",
      "   y_hat     rmse_RF  nrmse_RF     R2_RF\n",
      "0    SO3    0.194670  0.048763  0.908475\n",
      "1     Ba  350.591546  0.064620  0.621149\n",
      "2     Cr   15.885782  0.096726  0.699011\n",
      "3     Cu    4.841712  0.115947  0.762476\n",
      "4     Ga    1.442087  0.065549  0.812602\n",
      "5     Mo    9.549804  0.051593  0.909077\n",
      "6     Nb    0.750535  0.078225  0.772210\n",
      "7     Ni   12.451173  0.052259  0.907409\n",
      "8     Pb   11.217820  0.103715  0.445607\n",
      "9     Rb    4.671054  0.034101  0.945224\n",
      "10    Sr  181.141581  0.116861  0.546943\n",
      "11    Th    0.976529  0.068619  0.804389\n",
      "12     U    1.810907  0.125210  0.750651\n",
      "13     Y    2.016271  0.082297  0.841719\n",
      "14    Zn   92.698502  0.123912  0.237942\n",
      "15    Zr    9.273452  0.065413  0.882934\n"
     ]
    }
   ],
   "source": [
    "wells_scores = pd.DataFrame()\n",
    "pred = pd.DataFrame(C1_depth)\n",
    "        \n",
    "for col in y_values:\n",
    "    X = X_values\n",
    "    y = y_values[col]\n",
    "        \n",
    "                \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X,\n",
    "                                        y,\n",
    "                                        train_size   = 0.7,\n",
    "                                        random_state = 123,\n",
    "                                        shuffle      = True\n",
    "                                    )        \n",
    "    \n",
    "    # Evaluated Hyperparameters\n",
    "    \n",
    "    param_grid = {'n_estimators': [30,70,150],\n",
    "                    'max_features': [5, 10, 25],\n",
    "                    'max_depth'   : [None, 3, 10, 20]\n",
    "                    }\n",
    "\n",
    "    # Grid\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "            estimator  = RandomForestRegressor(random_state = 123),\n",
    "            param_grid = param_grid,\n",
    "            scoring    = 'neg_root_mean_squared_error',\n",
    "            n_jobs     = - 1,\n",
    "            cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "            refit      = True,\n",
    "            verbose    = 0,\n",
    "            return_train_score = True\n",
    "            )\n",
    "\n",
    "    grid.fit(X = X_train, y = y_train)\n",
    "\n",
    "    print(\"Final model best hyperparameters: \")        \n",
    "    print(\"\")       \n",
    "    print(grid.best_params_, \":\", grid.best_score_, grid.scoring)\n",
    "    print(\"\")\n",
    "    \n",
    "    # Test scores\n",
    "        \n",
    "    final_model = grid.best_estimator_\n",
    "    predictions = final_model.predict(X = X_test)\n",
    "        \n",
    "    rmse = mean_squared_error(\n",
    "            y_true  = y_test,\n",
    "            y_pred  = predictions,\n",
    "            squared = False\n",
    "            )\n",
    "                \n",
    "    nrmse = rmse/(y_test.max()-y_test.min())\n",
    "        \n",
    "    R2 = r2_score(y_test, predictions)        \n",
    "        \n",
    "    print(\"Wells Test Scores\")\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"NRMSE: {nrmse}\")        \n",
    "    print(f\"R2 score: {R2}\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "        \n",
    "                  \n",
    "    # Save well test validation\n",
    "                \n",
    "    wells_scores = wells_scores.append({\"y_hat\": col, f\"rmse_RF\": rmse, f\"nrmse_RF\": nrmse, f\"R2_RF\": R2}, ignore_index=True)\n",
    "                \n",
    "    wells_scores.to_excel(f\"Wells_TE_scores_RF.xlsx\")         \n",
    "    \n",
    "        \n",
    "    # WELL C1 MAYOR ELEMENTS PREDICTIONS \n",
    "                \n",
    "    X_test_C1 = Well_C1\n",
    "    y_test_C1 = y_values[col]\n",
    "    \n",
    "    C1_predictions = final_model.predict(X_test_C1) \n",
    "    \n",
    "                   \n",
    "    # Save C1 predicted curves\n",
    "        \n",
    "    C1_pred = pd.DataFrame()\n",
    "\n",
    "    C1_pred = C1_pred.assign(Predictions = C1_predictions.flatten().tolist())        \n",
    "                \n",
    "    pred=pd.concat([pred,C1_pred],axis=1)\n",
    "        \n",
    "    pred.columns=pred.columns.str.replace('Predictions', f\"{col}\")\n",
    "        \n",
    "    pred.to_excel(f\"C1_TE_pred_RF.xlsx\")       \n",
    "              \n",
    "    print(\"\")\n",
    "                \n",
    "print(f\"Well test validation\")\n",
    "print(wells_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c8980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59d1286e",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b40ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col= ['Well']\n",
    "categorical = ['c' if col in cat_col else 'q' for col in X_values.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4a003c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 5, 'subsample': 0.5} : -0.18552138002451043 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 66\n",
      "\n",
      "Wells Test Scores\n",
      "SO3:\n",
      "RMSE: 0.16058860209109163\n",
      "NRMSE: 0.04022569118481125\n",
      "R2 score: 0.9377165783128505\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 10, 'subsample': 0.5} : -1039.3949601650413 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 124\n",
      "\n",
      "Wells Test Scores\n",
      "Ba:\n",
      "RMSE: 407.11820020636173\n",
      "NRMSE: 0.07503838784861876\n",
      "R2 score: 0.4891338919817757\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 1} : -17.91712964907936 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 29\n",
      "\n",
      "Wells Test Scores\n",
      "Cr:\n",
      "RMSE: 18.018196664856593\n",
      "NRMSE: 0.10971031425747602\n",
      "R2 score: 0.6127809081746913\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': None, 'subsample': 1} : -5.02880623837629 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 302\n",
      "\n",
      "Wells Test Scores\n",
      "Cu:\n",
      "RMSE: 5.174633329332837\n",
      "NRMSE: 0.12391953853483048\n",
      "R2 score: 0.7286885551745248\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': None, 'subsample': 0.5} : -1.3609042200125785 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 361\n",
      "\n",
      "Wells Test Scores\n",
      "Ga:\n",
      "RMSE: 1.4559873880727783\n",
      "NRMSE: 0.06618124491239902\n",
      "R2 score: 0.8089716077272313\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5} : -14.560879996666005 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 53\n",
      "\n",
      "Wells Test Scores\n",
      "Mo:\n",
      "RMSE: 9.63087526117439\n",
      "NRMSE: 0.05203066051417823\n",
      "R2 score: 0.907526259928735\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 3, 'subsample': 1} : -0.6627692744093122 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 396\n",
      "\n",
      "Wells Test Scores\n",
      "Nb:\n",
      "RMSE: 0.6939304248924982\n",
      "NRMSE: 0.07232532827343989\n",
      "R2 score: 0.8052733259938402\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 3, 'subsample': 0.5} : -13.499085931155761 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 658\n",
      "\n",
      "Wells Test Scores\n",
      "Ni:\n",
      "RMSE: 11.042133538753644\n",
      "NRMSE: 0.04634537454350818\n",
      "R2 score: 0.9271791897901173\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 3, 'subsample': 1} : -7.48842297486532 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 380\n",
      "\n",
      "Wells Test Scores\n",
      "Pb:\n",
      "RMSE: 10.299851947520427\n",
      "NRMSE: 0.09522830850569683\n",
      "R2 score: 0.5326281333294498\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 3, 'subsample': 1} : -4.796000151231642 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 382\n",
      "\n",
      "Wells Test Scores\n",
      "Rb:\n",
      "RMSE: 4.456859886774763\n",
      "NRMSE: 0.032537257950632656\n",
      "R2 score: 0.9501321908995469\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 5, 'subsample': 0.5} : -183.39425130651094 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 26\n",
      "\n",
      "Wells Test Scores\n",
      "Sr:\n",
      "RMSE: 187.89342120507845\n",
      "NRMSE: 0.12121734292221148\n",
      "R2 score: 0.512538713341631\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5} : -0.9325964540972357 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 35\n",
      "\n",
      "Wells Test Scores\n",
      "Th:\n",
      "RMSE: 0.998745439819335\n",
      "NRMSE: 0.07017988899190196\n",
      "R2 score: 0.7953870984407329\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 5, 'subsample': 0.5} : -1.8563713609875572 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 486\n",
      "\n",
      "Wells Test Scores\n",
      "U:\n",
      "RMSE: 1.8383610100357595\n",
      "NRMSE: 0.12710812578853165\n",
      "R2 score: 0.7430335448649352\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': 20, 'subsample': 0.5} : -1.7813334814966224 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 391\n",
      "\n",
      "Wells Test Scores\n",
      "Y:\n",
      "RMSE: 1.8490168975402312\n",
      "NRMSE: 0.07547007745062169\n",
      "R2 score: 0.8668896685070621\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.01, 'max_depth': None, 'subsample': 0.5} : -81.66842244864267 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 144\n",
      "\n",
      "Wells Test Scores\n",
      "Zn:\n",
      "RMSE: 94.90188239000388\n",
      "NRMSE: 0.12685748611413133\n",
      "R2 score: 0.2012839373698676\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 5, 'subsample': 0.5} : -9.382111692160452 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 47\n",
      "\n",
      "Wells Test Scores\n",
      "Zr:\n",
      "RMSE: 9.932274434082055\n",
      "NRMSE: 0.07006033073235116\n",
      "R2 score: 0.8657089054945544\n",
      "\n",
      "\n",
      "\n",
      "Well test validation\n",
      "   y_hat    rmse_XGB  nrmse_XGB    R2_XGB\n",
      "0    SO3    0.160589   0.040226  0.937717\n",
      "1     Ba  407.118200   0.075038  0.489134\n",
      "2     Cr   18.018197   0.109710  0.612781\n",
      "3     Cu    5.174633   0.123920  0.728689\n",
      "4     Ga    1.455987   0.066181  0.808972\n",
      "5     Mo    9.630875   0.052031  0.907526\n",
      "6     Nb    0.693930   0.072325  0.805273\n",
      "7     Ni   11.042134   0.046345  0.927179\n",
      "8     Pb   10.299852   0.095228  0.532628\n",
      "9     Rb    4.456860   0.032537  0.950132\n",
      "10    Sr  187.893421   0.121217  0.512539\n",
      "11    Th    0.998745   0.070180  0.795387\n",
      "12     U    1.838361   0.127108  0.743034\n",
      "13     Y    1.849017   0.075470  0.866890\n",
      "14    Zn   94.901882   0.126857  0.201284\n",
      "15    Zr    9.932274   0.070060  0.865709\n"
     ]
    }
   ],
   "source": [
    "wells_scores = pd.DataFrame()\n",
    "pred = pd.DataFrame(C1_depth)\n",
    "        \n",
    "for col in y_values:\n",
    "    X = X_values\n",
    "    y = y_values[col]\n",
    "        \n",
    "                \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X,\n",
    "                                        y,\n",
    "                                        train_size   = 0.7,\n",
    "                                        random_state = 123,\n",
    "                                        shuffle      = True\n",
    "                                    )        \n",
    "    \n",
    "    # Evaluated Hyperparameters    \n",
    "    \n",
    "    param_grid = {'max_depth'        : [None, 1, 3, 5, 10, 20],\n",
    "                  'subsample'        : [0.5, 1],\n",
    "                  'learning_rate'    : [0.001, 0.01, 0.1],\n",
    "                  'booster'          : ['gbtree']\n",
    "                 }\n",
    "\n",
    "\n",
    "    # Creation of validation set\n",
    "    \n",
    "    np.random.seed(123)\n",
    "    idx_validacion = np.random.choice(\n",
    "                        X_train.shape[0],\n",
    "                        size=int(X_train.shape[0]*0.1), \n",
    "                        replace=False\n",
    "                        )\n",
    "\n",
    "    X_val = X_train.iloc[idx_validacion, :].copy()\n",
    "    y_val = y_train.iloc[idx_validacion].copy()\n",
    "\n",
    "    X_train_grid = X_train.reset_index(drop = True).drop(idx_validacion, axis = 0).copy()\n",
    "    y_train_grid = y_train.reset_index(drop = True).drop(idx_validacion, axis = 0).copy()\n",
    "\n",
    "        \n",
    "    fit_params = {\"eval_set\": [(X_val, y_val)],\n",
    "                   \"verbose\": False\n",
    "                    }\n",
    "\n",
    "    # Grid\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "            estimator  = XGBRegressor(\n",
    "                            n_estimators          = 1000,\n",
    "                            early_stopping_rounds = 5,\n",
    "                            eval_metric           = \"rmse\",\n",
    "                            tree_method           ='hist',\n",
    "                            enable_categorical    =True,\n",
    "                            random_state          = 123,\n",
    "                            feature_types         = categorical,\n",
    "                        ),\n",
    "            param_grid = param_grid,\n",
    "            scoring    = 'neg_root_mean_squared_error',\n",
    "            n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "            cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n",
    "            refit      = True,\n",
    "            verbose    = 0,\n",
    "            return_train_score = True\n",
    "            )\n",
    "\n",
    "    grid.fit(X = X_train_grid, y = y_train_grid, **fit_params)\n",
    "\n",
    "    print(\"Final model best hyperparameters: \")        \n",
    "    print(\"\")       \n",
    "    print(grid.best_params_, \":\", grid.best_score_, grid.scoring)\n",
    "    print(\"\")\n",
    "    n_trees_incluid = len(grid.best_estimator_.get_booster().get_dump())\n",
    "    print(f\"Final trees early stopping: {n_trees_incluid}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Test scores       \n",
    "    \n",
    "    final_model = grid.best_estimator_\n",
    "    predictions = final_model.predict(X_test)\n",
    "        \n",
    "    rmse = mean_squared_error(\n",
    "            y_true  = y_test,\n",
    "            y_pred  = predictions,\n",
    "            squared = False\n",
    "               )\n",
    "                \n",
    "    nrmse = rmse/(y_test.max()-y_test.min())\n",
    "        \n",
    "    R2 = r2_score(y_test, predictions)        \n",
    "        \n",
    "    print(\"Wells Test Scores\")\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"NRMSE: {nrmse}\")        \n",
    "    print(f\"R2 score: {R2}\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Save well test validation\n",
    "                \n",
    "    wells_scores = wells_scores.append({\"y_hat\":col,f\"rmse_XGB\": rmse, f\"nrmse_XGB\": nrmse, f\"R2_XGB\": R2}, ignore_index=True)\n",
    "                \n",
    "    wells_scores.to_excel(f\"Wells_TE_scores_XGB.xlsx\") \n",
    "        \n",
    "    \n",
    "    # WELL C1 MAYOR ELEMENTS PREDICTIONS \n",
    "                \n",
    "    X_test_C1 = Well_C1\n",
    "    y_test_C1 = y_values[col]\n",
    "    \n",
    "    C1_predictions = final_model.predict(X_test_C1) \n",
    "    \n",
    "       \n",
    "    # Save C1 predicted curves\n",
    "        \n",
    "    C1_pred = pd.DataFrame()\n",
    "\n",
    "    C1_pred = C1_pred.assign(Predictions = C1_predictions.flatten().tolist())        \n",
    "                \n",
    "    pred = pd.concat([pred,C1_pred],axis=1)\n",
    "        \n",
    "    pred.columns = pred.columns.str.replace('Predictions', f\"{col}\")\n",
    "        \n",
    "    pred.to_excel(f\"C1_TE_pred_XGB.xlsx\")  \n",
    "    \n",
    "    print(\"\")\n",
    "                \n",
    "print(f\"Well test validation\")\n",
    "print(wells_scores)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138b84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb19bce7",
   "metadata": {},
   "source": [
    "## Gradient Boosting: HistGradientBoostingregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87f75ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_values['Well']=X_values['Well'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0035814",
   "metadata": {},
   "outputs": [],
   "source": [
    "Well_C1_=Well_C1.copy()\n",
    "\n",
    "cols = list(Well_C1_.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "Well_C1_ = Well_C1_[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab3b8e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 1, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 5} : -0.1972342513448043 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 48\n",
      "\n",
      "Wells Test Scores\n",
      "SO3:\n",
      "RMSE: 0.16927289608764778\n",
      "NRMSE: 0.042401011997837725\n",
      "R2 score: 0.9307981224763262\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 10, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -1006.8535963665657 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 15\n",
      "\n",
      "Wells Test Scores\n",
      "Ba:\n",
      "RMSE: 392.65962454587753\n",
      "NRMSE: 0.07237344138442219\n",
      "R2 score: 0.5247757984397228\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 0, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 5} : -19.69292385508482 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 48\n",
      "\n",
      "Wells Test Scores\n",
      "Cr:\n",
      "RMSE: 16.557666549829886\n",
      "NRMSE: 0.10081734783677884\n",
      "R2 score: 0.6730115739820546\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 1, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -5.093143804227458 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 78\n",
      "\n",
      "Wells Test Scores\n",
      "Cu:\n",
      "RMSE: 4.431548323854816\n",
      "NRMSE: 0.10612450937807659\n",
      "R2 score: 0.8010151875192204\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 1, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 5} : -1.4721136342166854 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 62\n",
      "\n",
      "Wells Test Scores\n",
      "Ga:\n",
      "RMSE: 1.3382710461508736\n",
      "NRMSE: 0.06083050209776698\n",
      "R2 score: 0.8386121416675618\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 1, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 10} : -16.12555567052493 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 65\n",
      "\n",
      "Wells Test Scores\n",
      "Mo:\n",
      "RMSE: 10.084335479048157\n",
      "NRMSE: 0.05448047260425801\n",
      "R2 score: 0.8986131857058224\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 0, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -0.6472726875517534 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 60\n",
      "\n",
      "Wells Test Scores\n",
      "Nb:\n",
      "RMSE: 0.7519750397168051\n",
      "NRMSE: 0.07837506419952171\n",
      "R2 score: 0.7713346090112307\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 1, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -14.926024962175923 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 199\n",
      "\n",
      "Wells Test Scores\n",
      "Ni:\n",
      "RMSE: 11.367527822408109\n",
      "NRMSE: 0.04771109973577794\n",
      "R2 score: 0.9228241239039756\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 0, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -12.63080751000764 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 49\n",
      "\n",
      "Wells Test Scores\n",
      "Pb:\n",
      "RMSE: 10.838874115325714\n",
      "NRMSE: 0.10021189172113601\n",
      "R2 score: 0.4824301766437984\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 0, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 10} : -6.630367807618199 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 57\n",
      "\n",
      "Wells Test Scores\n",
      "Rb:\n",
      "RMSE: 5.737341277035912\n",
      "NRMSE: 0.04188539864932123\n",
      "R2 score: 0.9173612586222257\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 1, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3} : -180.69548333926264 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 57\n",
      "\n",
      "Wells Test Scores\n",
      "Sr:\n",
      "RMSE: 184.9105542272\n",
      "NRMSE: 0.11929297959416188\n",
      "R2 score: 0.5278930621779268\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 10, 'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 5} : -1.0112848082898769 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 77\n",
      "\n",
      "Wells Test Scores\n",
      "Th:\n",
      "RMSE: 1.0743465988001826\n",
      "NRMSE: 0.07549223459409542\n",
      "R2 score: 0.7632378790440566\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 1, 'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 5} : -1.977131171845583 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 49\n",
      "\n",
      "Wells Test Scores\n",
      "U:\n",
      "RMSE: 1.8619675244499163\n",
      "NRMSE: 0.12874032957614628\n",
      "R2 score: 0.7363917266644117\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 0, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 5} : -2.0772358464499385 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 98\n",
      "\n",
      "Wells Test Scores\n",
      "Y:\n",
      "RMSE: 1.9176835666883258\n",
      "NRMSE: 0.07827279864033983\n",
      "R2 score: 0.8568194922546688\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 1, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 10} : -78.74757780446693 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 53\n",
      "\n",
      "Wells Test Scores\n",
      "Zn:\n",
      "RMSE: 93.6520342666242\n",
      "NRMSE: 0.12518678594503635\n",
      "R2 score: 0.22218342144911407\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'l2_regularization': 0, 'learning_rate': 0.1, 'loss': 'absolute_error', 'max_depth': 3} : -9.851995139317843 neg_root_mean_squared_error\n",
      "\n",
      "Final trees early stopping: 174\n",
      "\n",
      "Wells Test Scores\n",
      "Zr:\n",
      "RMSE: 9.314670688711054\n",
      "NRMSE: 0.06570387411716197\n",
      "R2 score: 0.8818905077083863\n",
      "\n",
      "\n",
      "\n",
      "Well test validation\n",
      "   y_hat   rmse_HGBT  nrmse_HGBT   R2_HGBT\n",
      "0    SO3    0.169273    0.042401  0.930798\n",
      "1     Ba  392.659625    0.072373  0.524776\n",
      "2     Cr   16.557667    0.100817  0.673012\n",
      "3     Cu    4.431548    0.106125  0.801015\n",
      "4     Ga    1.338271    0.060831  0.838612\n",
      "5     Mo   10.084335    0.054480  0.898613\n",
      "6     Nb    0.751975    0.078375  0.771335\n",
      "7     Ni   11.367528    0.047711  0.922824\n",
      "8     Pb   10.838874    0.100212  0.482430\n",
      "9     Rb    5.737341    0.041885  0.917361\n",
      "10    Sr  184.910554    0.119293  0.527893\n",
      "11    Th    1.074347    0.075492  0.763238\n",
      "12     U    1.861968    0.128740  0.736392\n",
      "13     Y    1.917684    0.078273  0.856819\n",
      "14    Zn   93.652034    0.125187  0.222183\n",
      "15    Zr    9.314671    0.065704  0.881891\n"
     ]
    }
   ],
   "source": [
    "wells_scores = pd.DataFrame()\n",
    "pred = pd.DataFrame(C1_depth)\n",
    "        \n",
    "for col in y_values:\n",
    "    X = X_values\n",
    "    y = y_values[col]\n",
    "        \n",
    "                \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X,\n",
    "                                        y,\n",
    "                                        train_size   = 0.7,\n",
    "                                        random_state = 123,\n",
    "                                        shuffle      = True\n",
    "                                    )\n",
    "    \n",
    "    cat_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    \n",
    "    preprocessor = make_column_transformer(\n",
    "                        (\n",
    "                            OrdinalEncoder(\n",
    "                                dtype=int,\n",
    "                                handle_unknown=\"use_encoded_value\",\n",
    "                                unknown_value=-1,\n",
    "                                encoded_missing_value=-1\n",
    "                            ),\n",
    "                            cat_cols\n",
    "                        ),\n",
    "                        remainder=\"passthrough\",\n",
    "                        verbose_feature_names_out=False,\n",
    "                   ).set_output(transform=\"pandas\")\n",
    "        \n",
    "    X_train_prep = preprocessor.fit_transform(X_train)\n",
    "    X_test_prep = preprocessor.transform(X_test)\n",
    "\n",
    "\n",
    "    # Evaluated Hyperparameters\n",
    "    \n",
    "    param_grid = {'loss'             : ['squared_error', 'absolute_error'],\n",
    "                    'learning_rate'    : [0.001, 0.01, 0.1],\n",
    "                    'max_depth'        : [3, 5, 10, 20],\n",
    "                    'l2_regularization': [0, 1, 10]\n",
    "                    }\n",
    "\n",
    "    # Grid\n",
    "        \n",
    "    grid = GridSearchCV(\n",
    "            estimator  = HistGradientBoostingRegressor(\n",
    "                            max_iter            = 1000, \n",
    "                            random_state        = 123,\n",
    "                            early_stopping      = True,\n",
    "                            validation_fraction = 0.1,\n",
    "                            n_iter_no_change    = 10,\n",
    "                            tol                 = 1e-7,\n",
    "                            scoring             = 'loss',\n",
    "                            categorical_features = cat_cols\n",
    "                        ),\n",
    "            param_grid = param_grid,\n",
    "            scoring    = 'neg_root_mean_squared_error',\n",
    "            n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "            cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n",
    "            refit      = True,\n",
    "            verbose    = 0,\n",
    "            return_train_score = True\n",
    "            )\n",
    "\n",
    "    grid.fit(X = X_train_prep, y = y_train)\n",
    "        \n",
    "        \n",
    "    print(\"Final model best hyperparameters: \")        \n",
    "    print(\"\")       \n",
    "    print(grid.best_params_, \":\", grid.best_score_, grid.scoring)\n",
    "    print(\"\")        \n",
    "    print(f\"Final trees early stopping: {grid.best_estimator_.n_iter_}\")\n",
    "    print(\"\")    \n",
    "        \n",
    "        \n",
    "    # Test scores\n",
    "    \n",
    "    final_model = grid.best_estimator_\n",
    "    predictions = final_model.predict(X = X_test_prep)\n",
    "    \n",
    "    rmse = mean_squared_error(\n",
    "            y_true  = y_test,\n",
    "            y_pred  = predictions,\n",
    "            squared = False\n",
    "           )\n",
    "        \n",
    "    nrmse = rmse/(y_test.max()-y_test.min())\n",
    "        \n",
    "    R2 = r2_score(y_test, predictions)        \n",
    "        \n",
    "    print(\"Wells Test Scores\")\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"NRMSE: {nrmse}\")        \n",
    "    print(f\"R2 score: {R2}\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "        \n",
    "                  \n",
    "    # Save well test validation\n",
    "        \n",
    "    wells_scores = wells_scores.append({\"y_hat\":col,f\"rmse_HGBT\": rmse, f\"nrmse_HGBT\": nrmse,f\"R2_HGBT\": R2},ignore_index=True)\n",
    "                \n",
    "    wells_scores.to_excel(f\"Wells_TE_scores_HGBT.xlsx\")  \n",
    "    \n",
    "           \n",
    "    # WELL C1 MAYOR ELEMENTS PREDICTIONS \n",
    "                \n",
    "    X_test_C1 = Well_C1_\n",
    "    y_test_C1 = y_values[col]\n",
    "        \n",
    "    C1_predictions = final_model.predict(X_test_C1) \n",
    "    \n",
    "    # Save C1 predicted curves\n",
    "        \n",
    "    C1_pred = pd.DataFrame()\n",
    "\n",
    "    C1_pred = C1_pred.assign(Predictions = C1_predictions.flatten().tolist())        \n",
    "                \n",
    "    pred = pd.concat([pred,C1_pred],axis=1)\n",
    "        \n",
    "    pred.columns = pred.columns.str.replace('Predictions', f\"{col}\")\n",
    "        \n",
    "    pred.to_excel(f\"C1_TE_pred_HGBT.xlsx\")        \n",
    "    \n",
    "    print(\"\")\n",
    "        \n",
    "print(f\"Well test validation\")\n",
    "print(wells_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356f19e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f29f9d8",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d80dbbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Well_C1['Well']=Well_C1['Well'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa2ce760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 5000, 'subsample': 0.5} : -0.25951006732549947 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "SO3:\n",
      "RMSE: 0.1562008134419268\n",
      "NRMSE: 0.03912659804316097\n",
      "R2 score: 0.9410736405383229\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 500, 'subsample': 0.5} : -1024.8007921715557 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Ba:\n",
      "RMSE: 486.3248635728565\n",
      "NRMSE: 0.0896374412018644\n",
      "R2 score: 0.27101431035645185\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.001, 'max_depth': -1, 'n_estimators': 5000, 'subsample': 0.5} : -20.436242241032982 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Cr:\n",
      "RMSE: 14.707865377837495\n",
      "NRMSE: 0.08955416364204978\n",
      "R2 score: 0.7419918596306936\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 1000, 'subsample': 0.5} : -5.310902457185274 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Cu:\n",
      "RMSE: 4.221266196776937\n",
      "NRMSE: 0.1010887778602701\n",
      "R2 score: 0.819451272744148\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 5000, 'subsample': 0.5} : -1.5771391150049894 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Ga:\n",
      "RMSE: 1.4305937934080852\n",
      "NRMSE: 0.06502699060945842\n",
      "R2 score: 0.815576878924959\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 100, 'subsample': 0.5} : -15.661556839267334 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Mo:\n",
      "RMSE: 10.56650980008242\n",
      "NRMSE: 0.0570854122100617\n",
      "R2 score: 0.8886859389387006\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.5} : -0.6805405811271514 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Nb:\n",
      "RMSE: 0.7056121837489515\n",
      "NRMSE: 0.07354286682456342\n",
      "R2 score: 0.798662009477658\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 5000, 'subsample': 0.5} : -15.061269909132397 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Ni:\n",
      "RMSE: 11.20514545122674\n",
      "NRMSE: 0.0470295582759458\n",
      "R2 score: 0.9250132530890961\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 5000, 'subsample': 0.5} : -12.225663943616615 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Pb:\n",
      "RMSE: 12.79296132310394\n",
      "NRMSE: 0.11827859990465882\n",
      "R2 score: 0.27898752964416584\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 5000, 'subsample': 0.5} : -6.395257032988797 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Rb:\n",
      "RMSE: 4.659545051720572\n",
      "NRMSE: 0.03401695883020882\n",
      "R2 score: 0.9454933668878673\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500, 'subsample': 0.5} : -184.16305776148138 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Sr:\n",
      "RMSE: 182.23831407790257\n",
      "NRMSE: 0.11756901369652493\n",
      "R2 score: 0.5414397979720411\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 1000, 'subsample': 0.5} : -1.047323441279336 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Th:\n",
      "RMSE: 1.079383838179593\n",
      "NRMSE: 0.07584619155487675\n",
      "R2 score: 0.7610124829022289\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 5000, 'subsample': 0.5} : -2.005246406082087 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "U:\n",
      "RMSE: 1.8960215236126512\n",
      "NRMSE: 0.13109489431373025\n",
      "R2 score: 0.7266611525771356\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.5} : -1.9852841737415663 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Y:\n",
      "RMSE: 1.955756507252761\n",
      "NRMSE: 0.07982679621439841\n",
      "R2 score: 0.8510777556334901\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 100, 'subsample': 0.5} : -79.40118282858589 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Zn:\n",
      "RMSE: 93.8549231228957\n",
      "NRMSE: 0.1254579920541144\n",
      "R2 score: 0.21880962912734858\n",
      "\n",
      "\n",
      "\n",
      "Final model best hyperparameters: \n",
      "\n",
      "{'boosting_type': 'gbdt', 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 5000, 'subsample': 0.5} : -9.513476586082824 neg_root_mean_squared_error\n",
      "\n",
      "Wells Test Scores\n",
      "Zr:\n",
      "RMSE: 9.25902139954228\n",
      "NRMSE: 0.06531133486242632\n",
      "R2 score: 0.883297551630924\n",
      "\n",
      "\n",
      "\n",
      "Well test validation\n",
      "   y_hat   rmse_LGBM  nrmse_LGBM   R2_LGBM\n",
      "0    SO3    0.156201    0.039127  0.941074\n",
      "1     Ba  486.324864    0.089637  0.271014\n",
      "2     Cr   14.707865    0.089554  0.741992\n",
      "3     Cu    4.221266    0.101089  0.819451\n",
      "4     Ga    1.430594    0.065027  0.815577\n",
      "5     Mo   10.566510    0.057085  0.888686\n",
      "6     Nb    0.705612    0.073543  0.798662\n",
      "7     Ni   11.205145    0.047030  0.925013\n",
      "8     Pb   12.792961    0.118279  0.278988\n",
      "9     Rb    4.659545    0.034017  0.945493\n",
      "10    Sr  182.238314    0.117569  0.541440\n",
      "11    Th    1.079384    0.075846  0.761012\n",
      "12     U    1.896022    0.131095  0.726661\n",
      "13     Y    1.955757    0.079827  0.851078\n",
      "14    Zn   93.854923    0.125458  0.218810\n",
      "15    Zr    9.259021    0.065311  0.883298\n"
     ]
    }
   ],
   "source": [
    "wells_scores = pd.DataFrame()\n",
    "pred = pd.DataFrame(C1_depth)\n",
    "    \n",
    "for col in y_values:\n",
    "    X = X_values\n",
    "    y = y_values[col]\n",
    "        \n",
    "                \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X,\n",
    "                                        y,\n",
    "                                        train_size   = 0.7,\n",
    "                                        random_state = 123,\n",
    "                                        shuffle      = True\n",
    "                                    )        \n",
    "    \n",
    "    # Evaluated Hyperparameters\n",
    "    \n",
    "    param_grid = {'n_estimators'     : [100, 500, 1000, 5000],\n",
    "                  'max_depth'        : [-1, 1, 3, 5, 10, 20],\n",
    "                  'subsample'        : [0.5, 1],\n",
    "                  'learning_rate'    : [0.001, 0.01, 0.1],\n",
    "                  'boosting_type'    : ['gbdt']\n",
    "                     }\n",
    "\n",
    "    # Grid\n",
    "        \n",
    "    grid = GridSearchCV(\n",
    "            estimator  = LGBMRegressor(random_state=123),\n",
    "            param_grid = param_grid,\n",
    "            scoring    = 'neg_root_mean_squared_error',\n",
    "            n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "            cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n",
    "            refit      = True,\n",
    "            verbose    = 0,\n",
    "            return_train_score = True\n",
    "            )\n",
    "\n",
    "    grid.fit(X = X_train, y = y_train, categorical_feature='auto')\n",
    "\n",
    "    print(\"Final model best hyperparameters: \")        \n",
    "    print(\"\")       \n",
    "    print(grid.best_params_, \":\", grid.best_score_, grid.scoring)\n",
    "    print(\"\")\n",
    "    \n",
    "        \n",
    "    # Test scores\n",
    "        \n",
    "    final_model = grid.best_estimator_\n",
    "    predictions = final_model.predict(X = X_test)\n",
    "        \n",
    "    rmse = mean_squared_error(\n",
    "            y_true  = y_test,\n",
    "            y_pred  = predictions,\n",
    "            squared = False\n",
    "            )\n",
    "        \n",
    "    nrmse = rmse/(y_test.max()-y_test.min())\n",
    "        \n",
    "    R2 = r2_score(y_test, predictions)        \n",
    "        \n",
    "    print(\"Wells Test Scores\")\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"NRMSE: {nrmse}\")        \n",
    "    print(f\"R2 score: {R2}\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "        \n",
    "                  \n",
    "    # Save well test validation\n",
    "                \n",
    "    wells_scores = wells_scores.append({\"y_hat\":col,f\"rmse_LGBM\": rmse, f\"nrmse_LGBM\": nrmse, f\"R2_LGBM\": R2}, ignore_index=True)\n",
    "                \n",
    "    wells_scores.to_excel(f\"Wells_TE_scores_LGBM.xlsx\")         \n",
    "    \n",
    "        \n",
    "    # WELL C1 MAYOR ELEMENTS PREDICTIONS\n",
    "    \n",
    "    X_test_C1 = Well_C1\n",
    "    y_test_C1 = y_values[col]\n",
    "    \n",
    "    C1_predictions = final_model.predict(X_test_C1) \n",
    "    \n",
    "    # Save C1 predicted curves\n",
    "        \n",
    "    C1_pred = pd.DataFrame()\n",
    "\n",
    "    C1_pred = C1_pred.assign(Predictions = C1_predictions.flatten().tolist())        \n",
    "                \n",
    "    pred = pd.concat([pred,C1_pred],axis=1)\n",
    "        \n",
    "    pred.columns = pred.columns.str.replace('Predictions', f\"{col}\")\n",
    "        \n",
    "    pred.to_excel(f\"C1_TE_pred_LGBM.xlsx\") \n",
    "        \n",
    "        \n",
    "    print(\"\")\n",
    "        \n",
    "print(f\"Well test validation\")\n",
    "print(wells_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937bc575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1264c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
